   # monitor itself
   # my global config
   global:
     scrape_interval: 15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.
     evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.
     # scrape_timeout is set to the global default (10s).
   
   # Alertmanager configuration
   alerting:
     alertmanagers:
       - static_configs:
           - targets:
              - 127.0.0.1:9093
   
   # Load rules once and periodically evaluate them according to the global 'evaluation_interval'.
   rule_files:
      - "002.ALERTING_RULES/*.yml"
   
   # A scrape configuration containing exactly one endpoint to scrape:
   # Here it's Prometheus itself.
   scrape_configs:
     # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
     - job_name: "prometheus"
   
       # metrics_path defaults to '/metrics'
       # scheme defaults to 'http'.
   
       static_configs:
         - targets: ["localhost:9090"]
     - job_name: "ASUS_Node" # 监控本机(Ubuntu20.04 AMD64) , 参考: 000.Prometheus/004.NODE_EXPORTER
       metrics_path: "/metrics"
       static_configs:
         - targets: ["localhost:9100"]
     
     - job_name: "MySQL3309" # 监控自编译的MySQL: 3309 
       static_configs:
        - targets: ["localhost:9104"]

     - job_name: "MySQL3310" # 监控自编译的MySQL:  3310
       static_configs:
        - targets: ["localhost:9105"]